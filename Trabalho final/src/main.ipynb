{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sklearn.cluster\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.metrics.cluster\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import csv\n",
    "%matplotlib inline\n",
    "sns.set_context('poster')\n",
    "sns.set_palette('Paired', 10)\n",
    "sns.set_color_codes()\n",
    "\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "\n",
    "   os.environ['OMP_NUM_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.getcwd()\n",
    "data_dir = os.path.join(script_dir, '..', 'data')\n",
    "result_graph = os.path.join(script_dir, '..', 'result', 'graph')\n",
    "result_dados = os.path.join(script_dir, '..', 'result', 'dados.csv')\n",
    "\n",
    "result_dados = Path(result_dados)\n",
    "if result_dados.is_file():\n",
    "    os.remove(result_dados);\n",
    "\n",
    "def load_file(filename, className):\n",
    "  file_path = os.path.join(data_dir, filename)\n",
    "\n",
    "  try:\n",
    "    data = pd.read_csv(file_path)\n",
    "    data[className] = data[className].astype(str)\n",
    "    \n",
    "    dataOnly = data.drop(className, axis='columns')\n",
    "    labelsOnly = data[className]\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    dict = {'Filename': filename,\n",
    "        'DataOnly': dataOnly,\n",
    "        'Data': data,\n",
    "        'LabelsOnly': encoder.fit_transform(labelsOnly),\n",
    "        'LabelsEncoded': encoder.classes_,\n",
    "        'LabelsOnlyEncoded': labelsOnly\n",
    "        }\n",
    "\n",
    "    return dict\n",
    "  except FileNotFoundError:\n",
    "    print(f\"Arquivo {filename} não encontrado no diretório {data_dir}\")\n",
    "    return None\n",
    "  except pd.errors.EmptyDataError:\n",
    "    print(f\"Arquivo {filename} está vazio\")\n",
    "    return None\n",
    "  except pd.errors.ParserError:\n",
    "    print(f\"Erro ao analisar o arquivo {filename}\")\n",
    "    return None\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "                          executionId,\n",
    "                          cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True,\n",
    "                          printNumberFormatGraph = '0.4f',\n",
    "                          printNumberFormatLegend = None):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    #plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, (\"{:\"+printNumberFormatGraph+\"}\").format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    if(printNumberFormatLegend == None):\n",
    "      printNumberFormatLegend = printNumberFormatGraph\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Nomes verdadeiros')\n",
    "    plt.xlabel(('Nomes preditos\\nAcurácia={:'+printNumberFormatLegend+'}').format(accuracy))\n",
    "\n",
    "    result_graph_file = os.path.join(result_graph, ('{:}.png').format(executionId))\n",
    "    result_graph_file = Path(result_graph_file)\n",
    "    if result_graph_file.is_file():\n",
    "        os.remove(result_graph_file);\n",
    "\n",
    "    plt.savefig(result_graph_file, dpi=300, transparent=True);\n",
    "    #plt.show()\n",
    "    #return plt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo optdigitsaaa.csv não encontrado no diretório c:\\Fontes\\Doutorado\\Doc-Agrupamento\\Trabalho final\\src\\..\\data\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m data\u001b[38;5;241m=\u001b[39m load_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptdigitsaaa.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFilename\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#print(data[\"DataOnly\"].head())\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#print(data[\"Data\"].head())\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#print(data[\"LabelsOnly\"].head())\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabelsEncoded\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "data= load_file('optdigitsaaa.csv', \"class\")\n",
    "print(data[\"Filename\"])\n",
    "#print(data[\"DataOnly\"].head())\n",
    "#print(data[\"Data\"].head())\n",
    "#print(data[\"LabelsOnly\"].head())\n",
    "print(data[\"LabelsEncoded\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_algorithm(executionId, datasetName, dataset, cluster_function_name, cluster_function, function_args, function_kwds, sample_size=2):\n",
    "    start_time = time.time()\n",
    "    cluster = cluster_function(dataset[\"DataOnly\"], *function_args, **function_kwds)\n",
    "    time_taken = time.time() - start_time\n",
    "\n",
    "    labels_ = []\n",
    "\n",
    "    if(type(cluster).__module__ != np.__name__):\n",
    "        labels_ = cluster.labels_;\n",
    "    #else:\n",
    "    #    labels_ = cluster;\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit_transform(labels_),\n",
    "    clusterClasses = encoder.classes_\n",
    "\n",
    "    contingency = sklearn.metrics.cluster.contingency_matrix(dataset[\"LabelsOnly\"], labels_)\n",
    "\n",
    "    clusterLabels = labels_.astype(\"object\");\n",
    "\n",
    "    for idx2, newClusterLabel in enumerate(clusterClasses):\n",
    "        maxValue = -1;\n",
    "        maxLabel = \"\";\n",
    "        for idx, p in enumerate(dataset['LabelsEncoded']):\n",
    "            if(contingency[idx][idx2] > maxValue):\n",
    "                maxValue = contingency[idx][idx2];\n",
    "                maxLabel = dataset['LabelsEncoded'][idx];\n",
    "        \n",
    "        clusterLabels[clusterLabels==newClusterLabel] = maxLabel\n",
    "\n",
    "    confusion_matrix = sklearn.metrics._classification.confusion_matrix(dataset[\"LabelsOnlyEncoded\"], clusterLabels, normalize='all')\n",
    "    cmd = plot_confusion_matrix(executionId=executionId,\n",
    "                                cm=confusion_matrix,\n",
    "                                target_names=dataset[\"LabelsEncoded\"],\n",
    "                                title=(datasetName+' - '+cluster_function_name + ' (Id: {:})').format(executionId),\n",
    "                                printNumberFormatGraph=\".0%\",\n",
    "                                printNumberFormatLegend=\".1%\")\n",
    "    \n",
    "    purity_score = np.sum(np.amax(confusion_matrix, axis=0)) / np.sum(confusion_matrix)\n",
    "    jaccard_score = sklearn.metrics._classification.jaccard_score(dataset[\"LabelsOnlyEncoded\"], clusterLabels, average='micro')\n",
    "    adjusted_rand_score = sklearn.metrics.cluster.adjusted_rand_score(dataset[\"LabelsOnlyEncoded\"], clusterLabels)\n",
    "    accuracy_score = sklearn.metrics._classification.accuracy_score(dataset[\"LabelsOnlyEncoded\"], clusterLabels)\n",
    "\n",
    "    #classification_report = sklearn.metrics.classification_report(dataset[\"LabelsOnlyEncoded\"], clusterLabels, target_names=dataset[\"LabelsEncoded\"], zero_division=0)\n",
    "\n",
    "    result = {'ClusterFunctionName': cluster_function_name,\n",
    "        'Cluster': cluster,\n",
    "        'TimeTaken': time_taken,\n",
    "        'ClusterLabels': clusterLabels,\n",
    "        'AccuracyScore': accuracy_score,\n",
    "        'PurityScore': purity_score,\n",
    "        'AdjustedRandScore': adjusted_rand_score,\n",
    "        'JaccardScore': jaccard_score,\n",
    "        #'ContingencyMatrix': contingency,\n",
    "        'ConfusionMatrix': confusion_matrix,\n",
    "        #'ClassificationReport': classification_report,\n",
    "        #'ConfusionMatrixDisplay': cmd\n",
    "        }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[4mRice Dataset\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[4mYeast Dataset\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[4mBankruptcy Dataset\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[4mObesity Dataset\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[4mMagic Dataset\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[4mHandwritten Dataset\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[4mPen-Based Dataset\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataList = {\n",
    "        #'Iris': \"iris.csv\",\n",
    "        'Rice': \"Rice_Cammeo_Osmancik.csv\",\n",
    "        'Yeast' : 'yeast.csv',\n",
    "        'Bankruptcy': 'taiwanese-bankruptcy.csv',\n",
    "        'Obesity': 'Obesity.csv', # não - gráficos feios\n",
    "        'Magic': 'magic gamma telescope.csv',\n",
    "        'Handwritten': 'optdigits.csv',\n",
    "        'Pen-Based': 'pendigits.csv'\n",
    "        }\n",
    "\n",
    "parametros = [{\n",
    "        'RandomSeed': 10,\n",
    "        'Nr. Cluster': 1,\n",
    "        'Eps': 0.1,\n",
    "        'Linkage': \"Ward\",\n",
    "        'Threshold':0.1,\n",
    "        'Max. Iter':100,\n",
    "        'Min Samples': 0.1\n",
    "        },\n",
    "        {\n",
    "        'RandomSeed': 57,\n",
    "        'Nr. Cluster': 1.5,\n",
    "        'Eps': 0.5,\n",
    "        'Linkage': \"Complete\",\n",
    "        'Threshold':0.5,\n",
    "        'Max. Iter':150,\n",
    "        'Min Samples': 0.3\n",
    "        },\n",
    "        {\n",
    "        'RandomSeed': 965,\n",
    "        'Nr. Cluster': 2,\n",
    "        'Eps': 1.0,\n",
    "        'Linkage': \"Average\",\n",
    "        'Threshold':1.0,\n",
    "        'Max. Iter':300,\n",
    "        'Min Samples': 0.5\n",
    "        },\n",
    "        {\n",
    "        'RandomSeed': 7821,\n",
    "        'Nr. Cluster': 3,\n",
    "        'Eps': 1.5,\n",
    "        'Linkage': \"Single\",\n",
    "        'Threshold':1.5,\n",
    "        'Max. Iter':500,\n",
    "        'Min Samples': 0.8\n",
    "        }]\n",
    "\n",
    "executionId = 1;\n",
    "\n",
    "with open(result_dados, 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file, lineterminator=\"\\n\")\n",
    "\n",
    "    for dataKey in dataList:\n",
    "        print(color.BOLD + color.UNDERLINE + dataKey + \" Dataset\" + color.END + \"\\n\")\n",
    "        \n",
    "        data = load_file(dataList[dataKey], \"class\")\n",
    "\n",
    "        for param in parametros:\n",
    "             clusterLength = int( len(data[\"LabelsEncoded\"]) * param[\"Nr. Cluster\"] )\n",
    "\n",
    "             #if(executionId<96):\n",
    "             #   continue;\n",
    "\n",
    "             #'''\n",
    "             localParam = param.copy()\n",
    "             localParam[\"ID\"]=executionId;\n",
    "             k_means = sklearn.cluster.KMeans(clusterLength, n_init='auto', random_state=param[\"RandomSeed\"], max_iter=param[\"Max. Iter\"])\n",
    "             clusterResult = benchmark_algorithm(executionId, dataKey, data, \"K-means\", k_means.fit, (), {});\n",
    "             localParam.update({'Dataset': dataKey, 'Cluster': \"K-means\", 'Eps': None, 'Linkage': None, 'Threshold': None, 'Min Samples': None});\n",
    "             localParam.update({'Time Taken (seg)': clusterResult['TimeTaken'], 'Accuracy Score': clusterResult['AccuracyScore'], 'Purity Score': clusterResult['PurityScore'], 'Adjusted Rand Index': clusterResult['AdjustedRandScore'], 'Jaccard Score': clusterResult['JaccardScore']});\n",
    "\n",
    "             if(executionId==1):\n",
    "                  writer.writerow(localParam.keys())\n",
    "             writer.writerow(localParam.values())\n",
    "\n",
    "             executionId+=1;\n",
    "             #'''\n",
    "\n",
    "             #'''\n",
    "             localParam = param.copy()\n",
    "             localParam[\"ID\"]=executionId;\n",
    "             dbscan = sklearn.cluster.DBSCAN(eps=param[\"Eps\"])\n",
    "             clusterResult = benchmark_algorithm(executionId, dataKey, data, \"DBScan\", dbscan.fit, (), {})\n",
    "             localParam.update({'Dataset': dataKey, 'Cluster': \"DBScan\", 'RandomSeed': None, 'Linkage': None, 'Threshold': None, 'Max. Iter': None, 'Min Samples': None});\n",
    "             localParam.update({'Time Taken (seg)': clusterResult['TimeTaken'], 'Accuracy Score': clusterResult['AccuracyScore'], 'Purity Score': clusterResult['PurityScore'], 'Adjusted Rand Index': clusterResult['AdjustedRandScore'], 'Jaccard Score': clusterResult['JaccardScore']});\n",
    "             writer.writerow(localParam.values())\n",
    "             executionId+=1;\n",
    "             #'''\n",
    "\n",
    "             #'''\n",
    "             localParam = param.copy()\n",
    "             localParam[\"ID\"]=executionId;\n",
    "             agglomerative = sklearn.cluster.AgglomerativeClustering(clusterLength, linkage=param[\"Linkage\"].lower())\n",
    "             clusterResult = benchmark_algorithm(executionId, dataKey, data, \"Agglomerative Clustering - \"+param[\"Linkage\"], agglomerative.fit, (), {})\n",
    "             localParam.update({'Dataset': dataKey, 'Cluster': \"Agglomerative Clustering - \"+param[\"Linkage\"], 'RandomSeed': None, 'Eps': None, 'Threshold': None, 'Max. Iter': None, 'Min Samples': None});\n",
    "             localParam.update({'Time Taken (seg)': clusterResult['TimeTaken'], 'Accuracy Score': clusterResult['AccuracyScore'], 'Purity Score': clusterResult['PurityScore'], 'Adjusted Rand Index': clusterResult['AdjustedRandScore'], 'Jaccard Score': clusterResult['JaccardScore']});\n",
    "             writer.writerow(localParam.values())\n",
    "             executionId+=1;\n",
    "             #'''\n",
    "\n",
    "             #'''\n",
    "             localParam = param.copy()\n",
    "             localParam[\"ID\"]=executionId;\n",
    "             spectral = sklearn.cluster.SpectralClustering(clusterLength, random_state=param[\"RandomSeed\"], n_jobs=1)\n",
    "             clusterResult = benchmark_algorithm(executionId, dataKey, data, \"Spectral Clustering\", spectral.fit, (), {})\n",
    "             localParam.update({'Dataset': dataKey, 'Cluster': \"Spectral Clustering\", 'Eps': None, 'Linkage': None, 'Threshold': None, 'Max. Iter': None, 'Min Samples': None});\n",
    "             localParam.update({'Time Taken (seg)': clusterResult['TimeTaken'], 'Accuracy Score': clusterResult['AccuracyScore'], 'Purity Score': clusterResult['PurityScore'], 'Adjusted Rand Index': clusterResult['AdjustedRandScore'], 'Jaccard Score': clusterResult['JaccardScore']});\n",
    "             writer.writerow(localParam.values())\n",
    "             executionId+=1;\n",
    "             #'''\n",
    "\n",
    "             #'''\n",
    "             localParam = param.copy()\n",
    "             localParam[\"ID\"]=executionId;\n",
    "             birch = sklearn.cluster.Birch(n_clusters=clusterLength, threshold=param[\"Threshold\"])\n",
    "             clusterResult = benchmark_algorithm(executionId, dataKey, data, \"Birch\", birch.fit, (), {})\n",
    "             localParam.update({'Dataset': dataKey, 'Cluster': \"Birch\", 'RandomSeed': None, 'Eps': None, 'Linkage': None, 'Max. Iter': None, 'Min Samples': None});\n",
    "             localParam.update({'Time Taken (seg)': clusterResult['TimeTaken'], 'Accuracy Score': clusterResult['AccuracyScore'], 'Purity Score': clusterResult['PurityScore'], 'Adjusted Rand Index': clusterResult['AdjustedRandScore'], 'Jaccard Score': clusterResult['JaccardScore']});\n",
    "             writer.writerow(localParam.values())\n",
    "             executionId+=1;\n",
    "             #'''\n",
    "\n",
    "             #'''\n",
    "             localParam = param.copy()\n",
    "             localParam[\"ID\"]=executionId;\n",
    "             meanShift = sklearn.cluster.MeanShift(n_jobs=1, max_iter=param[\"Max. Iter\"])\n",
    "             clusterResult = benchmark_algorithm(executionId, dataKey, data, \"Mean Shift\", meanShift.fit, (), {})\n",
    "             localParam.update({'Dataset': dataKey, 'Cluster': \"Mean Shift\", 'RandomSeed': None, 'Nr. Cluster': None, 'Eps': None, 'Linkage': None, 'Threshold': None, 'Min Samples': None});\n",
    "             localParam.update({'Time Taken (seg)': clusterResult['TimeTaken'], 'Accuracy Score': clusterResult['AccuracyScore'], 'Purity Score': clusterResult['PurityScore'], 'Adjusted Rand Index': clusterResult['AdjustedRandScore'], 'Jaccard Score': clusterResult['JaccardScore']});\n",
    "             writer.writerow(localParam.values())\n",
    "             executionId+=1;\n",
    "             #'''\n",
    "\n",
    "             #'''\n",
    "             localParam = param.copy()\n",
    "             localParam[\"ID\"]=executionId;\n",
    "             affinity_prop = sklearn.cluster.AffinityPropagation(random_state=param[\"RandomSeed\"], max_iter=param[\"Max. Iter\"])\n",
    "             clusterResult = benchmark_algorithm(executionId, dataKey, data, \"Affinity Propagation\", affinity_prop.fit, (), {})\n",
    "             localParam.update({'Dataset': dataKey, 'Cluster': \"Affinity Propagation\", 'Nr. Cluster': None, 'Eps': None, 'Linkage': None, 'Threshold': None, 'Min Samples': None});\n",
    "             localParam.update({'Time Taken (seg)': clusterResult['TimeTaken'], 'Accuracy Score': clusterResult['AccuracyScore'], 'Purity Score': clusterResult['PurityScore'], 'Adjusted Rand Index': clusterResult['AdjustedRandScore'], 'Jaccard Score': clusterResult['JaccardScore']});\n",
    "             writer.writerow(localParam.values())\n",
    "             executionId+=1;\n",
    "             #'''\n",
    "\n",
    "             #'''\n",
    "             localParam = param.copy()\n",
    "             localParam[\"ID\"]=executionId;\n",
    "             optics= sklearn.cluster.OPTICS(min_samples = param[\"Min Samples\"], eps = param[\"Eps\"], n_jobs=1)\n",
    "             clusterResult = benchmark_algorithm(executionId, dataKey, data, \"Optics\", optics.fit, (), {})\n",
    "             localParam.update({'Dataset': dataKey, 'Cluster': \"Optics\", 'RandomSeed': None, 'Nr. Cluster': None, 'Linkage': None, 'Threshold': None, 'Max. Iter': None});\n",
    "             localParam.update({'Time Taken (seg)': clusterResult['TimeTaken'], 'Accuracy Score': clusterResult['AccuracyScore'], 'Purity Score': clusterResult['PurityScore'], 'Adjusted Rand Index': clusterResult['AdjustedRandScore'], 'Jaccard Score': clusterResult['JaccardScore']});\n",
    "             writer.writerow(localParam.values())\n",
    "             executionId+=1;\n",
    "             #'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
